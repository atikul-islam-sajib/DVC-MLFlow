{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import joblib\n",
    "\n",
    "\n",
    "def dump(value=None, filename=None):\n",
    "    if (value is not None) and (filename is not None):\n",
    "        joblib.dump(value=value, filename=filename)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"The value and filename are required\".capitalize())\n",
    "\n",
    "\n",
    "def load(filename=None):\n",
    "    if filename is not None:\n",
    "        return joblib.load(filename=filename)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"The filename is required\".capitalize())\n",
    "\n",
    "\n",
    "def config():\n",
    "    with open(\"./config.yml\", \"r\") as file:\n",
    "        return yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from utils import dump, load, config\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class Loader:\n",
    "    def __init__(self, dataset=None, batch_size=64, split_size=0.25):\n",
    "        self.datframe = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.split_size = split_size\n",
    "\n",
    "        self.PROCESSED_PATH = config()[\"path\"][\"PROCESSED_PATH\"]\n",
    "\n",
    "    def normalized_dataset(self, dataset):\n",
    "        if isinstance(dataset, torch.Tensor):\n",
    "            scaler = StandardScaler()\n",
    "            return torch.tensor(scaler.fit_transform(dataset))\n",
    "        else:\n",
    "            raise TypeError(\"The dataset must be a torch tensor\")\n",
    "\n",
    "    def preprocessing(self):\n",
    "        self.dataset = pd.read_csv(self.datframe)\n",
    "\n",
    "        if isinstance(self.dataset, pd.DataFrame):\n",
    "            if \"id\" in self.dataset.columns:\n",
    "                self.dataset.drop([\"id\"], axis=1, inplace=True)\n",
    "            else:\n",
    "                print(\"The dataset does not have an id column\")\n",
    "\n",
    "            if \"diagnosis\" in self.dataset.columns:\n",
    "                if (\n",
    "                    \"M\" in self.dataset[\"diagnosis\"].unique()\n",
    "                    and \"B\" in self.dataset[\"diagnosis\"].unique()\n",
    "                ):\n",
    "                    self.dataset[\"diagnosis\"] = self.dataset[\"diagnosis\"].map(\n",
    "                        {\"B\": 0, \"M\": 1}\n",
    "                    )\n",
    "                else:\n",
    "                    print(\"The dataset does not have the correct diagnosis values\")\n",
    "            else:\n",
    "                print(\"The dataset does not have a diagnosis column\")\n",
    "\n",
    "            X = self.dataset.iloc[:, 1:]\n",
    "            y = self.dataset.iloc[:, 0]\n",
    "\n",
    "            y = y.astype(int)\n",
    "\n",
    "            X = torch.tensor(data=X.values, dtype=torch.float)\n",
    "            y = torch.tensor(data=y.values, dtype=torch.long)\n",
    "\n",
    "            X = self.normalized_dataset(dataset=X)\n",
    "\n",
    "            return {\"X\": X, \"y\": y}\n",
    "\n",
    "        else:\n",
    "            raise TypeError(\"The dataset must be a pandas DataFrame\")\n",
    "\n",
    "    def create_dataloader(self):\n",
    "        data = self.preprocessing()\n",
    "\n",
    "        if isinstance(data[\"X\"], torch.Tensor) and isinstance(data[\"y\"], torch.Tensor):\n",
    "            X = data[\"X\"]\n",
    "            y = data[\"y\"]\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=self.split_size, random_state=42\n",
    "            )\n",
    "\n",
    "            train_dataloader = DataLoader(\n",
    "                dataset=list(zip(X_train, y_train)),\n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=True,\n",
    "            )\n",
    "\n",
    "            test_dataloader = DataLoader(\n",
    "                dataset=list(zip(X_test, y_test)),\n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=True,\n",
    "            )\n",
    "\n",
    "            os.makedirs(self.PROCESSED_PATH, exist_ok=True)\n",
    "            for filename, value in [\n",
    "                (\"train_dataloader\", train_dataloader),\n",
    "                (\"test_dataloader\", test_dataloader),\n",
    "            ]:\n",
    "                dump(\n",
    "                    value=value,\n",
    "                    filename=os.path.join(self.PROCESSED_PATH, f\"{filename}.pkl\"),\n",
    "                )\n",
    "\n",
    "            print(\n",
    "                \"The dataloader has been saved in the folder {}\".format(\n",
    "                    self.PROCESSED_PATH\n",
    "                )\n",
    "            )\n",
    "\n",
    "    @staticmethod\n",
    "    def dataset_details():\n",
    "        PROCESSED_PATH = config()[\"path\"][\"PROCESSED_PATH\"]\n",
    "        FILES_PATH = config()[\"path\"][\"FILES_PATH\"]\n",
    "\n",
    "        if os.path.exists(PROCESSED_PATH):\n",
    "            train_dataloader = load(\n",
    "                filename=os.path.join(PROCESSED_PATH, \"train_dataloader.pkl\")\n",
    "            )\n",
    "            test_dataloader = load(\n",
    "                filename=os.path.join(PROCESSED_PATH, \"test_dataloader.pkl\")\n",
    "            )\n",
    "\n",
    "            X, y = next(iter(train_dataloader))\n",
    "\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"Train Data(Total)\": sum(X.size(0) for X, y in train_dataloader),\n",
    "                \"Test Data(Total)\": sum(X.size(0) for X, y in test_dataloader),\n",
    "                \"Data Shpe (Train)\": str(X.size()),\n",
    "            },\n",
    "            index=[\"Quantity\"],\n",
    "        ).T.to_csv(\n",
    "            os.path.join(FILES_PATH, \"dataset_details.csv\"),\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Data Loader for the Cancer\".capitalize()\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dataset\",\n",
    "        default=os.path.join(config()[\"path\"][\"RAW_PATH\"], \"breast-cancer.csv\"),\n",
    "        help=\"Defin the dataset\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--split_size\",\n",
    "        default=config()[\"data\"][\"split_size\"],\n",
    "        help=\"Defin the split size\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        default=config()[\"data\"][\"batch_size\"],\n",
    "        help=\"Defin the batch size\".capitalize(),\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    loader = Loader(\n",
    "        dataset=args.dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        split_size=args.split_size,\n",
    "    )\n",
    "\n",
    "    loader.create_dataloader()\n",
    "\n",
    "    loader.dataset_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "from utils import config\n",
    "from torchsummary import summary\n",
    "from torchview import draw_graph\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features=30):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.out_features = 128\n",
    "\n",
    "        self.layers = []\n",
    "\n",
    "        for _ in range(4):\n",
    "            self.layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(\n",
    "                        in_features=self.in_features, out_features=self.out_features\n",
    "                    ),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(num_features=self.out_features),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            self.in_features = self.out_features\n",
    "            self.out_features = self.out_features // 2\n",
    "\n",
    "        self.model = nn.Sequential(*self.layers)\n",
    "\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(in_features=self.in_features, out_features=1), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            x = self.model(x)\n",
    "            return self.out(x)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Input must be a torch.Tensor\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Model for breast Cancer\".title())\n",
    "    parser.add_argument(\n",
    "        \"--model\",\n",
    "        action=\"store_true\",\n",
    "        default=None,\n",
    "        help=\"Model for Breast Cancer\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--in_features\",\n",
    "        default=config()[\"model\"][\"in_features\"],\n",
    "        type=int,\n",
    "        help=\"Define the number of features\".capitalize(),\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.model:\n",
    "\n",
    "        model = Model(in_features=args.in_features)\n",
    "\n",
    "        summary(model=model, input_size=(30,))\n",
    "\n",
    "        draw_graph(model=model, input_data=torch.randn(32, 30)).visual_graph.render(\n",
    "            filename=os.path.join(config()[\"path\"][\"FILES_PATH\"], \"Model\"),\n",
    "            format=\"jpeg\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.nn as nn\n",
    "from model import Model\n",
    "import torch.optim as optim\n",
    "from utils import load, config\n",
    "\n",
    "\n",
    "def load_dataloader():\n",
    "    processed_path = config()[\"path\"][\"PROCESSED_PATH\"]\n",
    "\n",
    "    if os.path.exists(processed_path):\n",
    "        train_dataloader = load(\n",
    "            filename=os.path.join(processed_path, \"train_dataloader.pkl\")\n",
    "        )\n",
    "\n",
    "        test_dataloader = load(\n",
    "            filename=os.path.join(processed_path, \"test_dataloader.pkl\")\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"train_dataloader\": train_dataloader,\n",
    "            \"test_dataloader\": test_dataloader,\n",
    "        }\n",
    "\n",
    "\n",
    "def helpers(**kwargs):\n",
    "    lr = kwargs[\"lr\"]\n",
    "    adam = kwargs[\"adam\"]\n",
    "    SGD = kwargs[\"SGD\"]\n",
    "    beta1 = kwargs[\"beta1\"]\n",
    "    beta2 = kwargs[\"beta2\"]\n",
    "    momentum = kwargs[\"momentum\"]\n",
    "\n",
    "    netBreastCancer = Model()\n",
    "\n",
    "    if adam:\n",
    "        optimizer = optim.Adam(\n",
    "            params=netBreastCancer.parameters(), lr=lr, betas=(beta1, beta2)\n",
    "        )\n",
    "\n",
    "    elif SGD:\n",
    "        optimizer = optim.SGD(\n",
    "            params=netBreastCancer.parameters(), lr=lr, momentum=momentum\n",
    "        )\n",
    "\n",
    "    criterion = nn.BCELoss(reduction=\"mean\")\n",
    "\n",
    "    dataloader = load_dataloader()\n",
    "\n",
    "    return {\n",
    "        \"model\": netBreastCancer,\n",
    "        \"optimizer\": optimizer,\n",
    "        \"criterion\": criterion,\n",
    "        \"train_dataloader\": dataloader[\"train_dataloader\"],\n",
    "        \"test_dataloader\": dataloader[\"test_dataloader\"],\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    init = helpers(\n",
    "        lr=0.01,\n",
    "        adam=True,\n",
    "        SGD=False,\n",
    "        beta1=0.9,\n",
    "        beta2=0.5,\n",
    "        momentum=0.9,\n",
    "    )\n",
    "\n",
    "    print(init[\"model\"])\n",
    "    print(init[\"train_dataloader\"])\n",
    "    print(init[\"test_dataloader\"])\n",
    "\n",
    "    assert init[\"optimizer\"].__class__.__name__ == \"Adam\"\n",
    "    assert init[\"criterion\"].__class__.__name__ == \"BCELoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import mlflow\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import config, dump, load\n",
    "from helper import helpers\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        epochs=100,\n",
    "        lr=0.01,\n",
    "        beta1=0.5,\n",
    "        beta2=0.999,\n",
    "        momentum=0.9,\n",
    "        step_size=7,\n",
    "        gamma=0.1,\n",
    "        adam=True,\n",
    "        SGD=False,\n",
    "        device=\"cpu\",\n",
    "        is_display=True,\n",
    "        lr_scheduler=False,\n",
    "    ):\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.adam = adam\n",
    "        self.SGD = SGD\n",
    "        self.momentum = momentum\n",
    "        self.step_size = step_size\n",
    "        self.gamma = gamma\n",
    "        self.device = device\n",
    "        self.is_display = is_display\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "\n",
    "        self.experiment_name = \"Breast Cancer Classification\"\n",
    "\n",
    "        self.init = helpers(\n",
    "            lr=self.lr,\n",
    "            beta1=self.beta1,\n",
    "            beta2=self.beta2,\n",
    "            momentum=self.momentum,\n",
    "            adam=self.adam,\n",
    "            SGD=self.SGD,\n",
    "        )\n",
    "\n",
    "        self.train_dataloader = self.init[\"train_dataloader\"]\n",
    "        self.valid_dataloader = self.init[\"test_dataloader\"]\n",
    "\n",
    "        self.model = self.init[\"model\"].to(self.device)\n",
    "        self.criterion = self.init[\"criterion\"]\n",
    "        self.optimizer = self.init[\"optimizer\"]\n",
    "\n",
    "        if self.lr_scheduler:\n",
    "            self.scheduler = StepLR(\n",
    "                optimizer=self.optimizer, step_size=self.step_size, gamma=self.gamma\n",
    "            )\n",
    "\n",
    "        self.history = {\"train_loss\": [], \"test_loss\": []}\n",
    "        self.loss = float(\"inf\")\n",
    "        self.config = config()\n",
    "\n",
    "        self.raw_data_path = self.config[\"path\"][\"RAW_PATH\"]\n",
    "        self.files_path = self.config[\"path\"][\"FILES_PATH\"]\n",
    "        self.train_models_path = self.config[\"path\"][\"TRAIN_MODEL_PATH\"]\n",
    "        self.best_model_path = self.config[\"path\"][\"BEST_MODEL_PATH\"]\n",
    "\n",
    "    def update_model(self, X, y):\n",
    "        if isinstance(X, torch.Tensor) and isinstance(y, torch.Tensor):\n",
    "            X = X.float()\n",
    "            y = y.float()\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            predicted = self.model(X)\n",
    "            predicted_loss = self.criterion(predicted, y)\n",
    "\n",
    "            predicted_loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            return predicted, predicted_loss.item()\n",
    "\n",
    "        else:\n",
    "            raise TypeError(\"X and y must be torch.Tensor\")\n",
    "\n",
    "    def display_progress(self, **kwargs):\n",
    "        if self.is_display:\n",
    "            print(\n",
    "                \"Epochs - [{}/{}] - Train Loss: {:.4f} - Test Loss: {:.4f} - train_accuracy: {:.4f} - test_accuracy: {:.4f}\".format(\n",
    "                    kwargs[\"epoch\"] + 1,\n",
    "                    self.epochs,\n",
    "                    np.mean(kwargs[\"train_loss\"]),\n",
    "                    np.mean(kwargs[\"test_loss\"]),\n",
    "                    accuracy_score(kwargs[\"train_actual\"], kwargs[\"train_pred\"]),\n",
    "                    accuracy_score(kwargs[\"valid_actual\"], kwargs[\"valid_pred\"]),\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                \"Epochs - [{}/{}] is completed\".format(kwargs[\"epoch\"] + 1, self.epochs)\n",
    "            )\n",
    "\n",
    "    def saved_models(self, epoch=None, train_loss=None):\n",
    "        torch.save(\n",
    "            self.model.state_dict(),\n",
    "            os.path.join(self.train_models_path, \"model{}.pth\".format(epoch)),\n",
    "        )\n",
    "\n",
    "        if train_loss is not None:\n",
    "            if self.loss > train_loss:\n",
    "                self.loss = train_loss\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"model\": self.model.state_dict(),\n",
    "                        \"loss\": train_loss,\n",
    "                        \"epoch\": epoch,\n",
    "                    },\n",
    "                    os.path.join(self.best_model_path, \"best_model.pth\"),\n",
    "                )\n",
    "        else:\n",
    "            raise ValueError(\"Train loss cannot be None\".capitalize())\n",
    "\n",
    "    def compute_model_performace(self, actual, predicted):\n",
    "        return {\n",
    "            \"accuracy\": accuracy_score(actual, predicted),\n",
    "            \"precision\": precision_score(actual, predicted),\n",
    "            \"recall\": recall_score(actual, predicted),\n",
    "            \"f1_score\": f1_score(actual, predicted),\n",
    "        }\n",
    "\n",
    "    def train(self):\n",
    "        mlflow.set_experiment(self.experiment_name)\n",
    "\n",
    "        with mlflow.start_run(\n",
    "            description=\"This is used for to track the Breast Cancer Classification Model loss\"\n",
    "        ) as run:\n",
    "\n",
    "            for epoch in tqdm(range(self.epochs)):\n",
    "                train_predcit = []\n",
    "                valid_predict = []\n",
    "                train_actual = []\n",
    "                valid_actual = []\n",
    "                train_loss = []\n",
    "                test_loss = []\n",
    "\n",
    "                for _, (X, y) in enumerate(self.train_dataloader):\n",
    "                    X, y = X.to(self.device), y.to(self.device)\n",
    "                    X = X.float()\n",
    "                    y = y.float()\n",
    "\n",
    "                    predicted, loss = self.update_model(X=X, y=y.unsqueeze(1))\n",
    "\n",
    "                    train_predcit.append(\n",
    "                        torch.where(predicted > 0.5, 1, 0).detach().cpu().numpy()\n",
    "                    )\n",
    "                    train_actual.append(\n",
    "                        torch.where(y > 0.5, 1, 0).detach().cpu().numpy()\n",
    "                    )\n",
    "\n",
    "                    train_loss.append(loss)\n",
    "\n",
    "                for _, (X, y) in enumerate(self.valid_dataloader):\n",
    "                    X, y = X.to(self.device), y.to(self.device)\n",
    "                    X = X.float()\n",
    "                    y = y.float()\n",
    "\n",
    "                    predicted = self.model(X)\n",
    "                    loss = self.criterion(predicted, y.unsqueeze(1))\n",
    "\n",
    "                    valid_predict.append(\n",
    "                        torch.where(predicted > 0.5, 1, 0).detach().cpu().numpy()\n",
    "                    )\n",
    "                    valid_actual.append(\n",
    "                        torch.where(y > 0.5, 1, 0).detach().cpu().numpy()\n",
    "                    )\n",
    "\n",
    "                    test_loss.append(loss.item())\n",
    "\n",
    "                if self.lr_scheduler:\n",
    "                    self.scheduler.step()\n",
    "\n",
    "                train_actual = np.concatenate(train_actual)\n",
    "                train_predcit = np.concatenate(train_predcit)\n",
    "                valid_actual = np.concatenate(valid_actual)\n",
    "                valid_predict = np.concatenate(valid_predict)\n",
    "\n",
    "                self.display_progress(\n",
    "                    epoch=epoch,\n",
    "                    train_loss=train_loss,\n",
    "                    test_loss=test_loss,\n",
    "                    train_pred=train_predcit,\n",
    "                    train_actual=train_actual,\n",
    "                    valid_pred=valid_predict,\n",
    "                    valid_actual=valid_actual,\n",
    "                )\n",
    "\n",
    "                self.saved_models(epoch=epoch + 1, train_loss=np.mean(train_loss))\n",
    "\n",
    "                self.history[\"train_loss\"].append(np.mean(train_loss))\n",
    "                self.history[\"test_loss\"].append(np.mean(test_loss))\n",
    "\n",
    "                train_performance = self.compute_model_performace(\n",
    "                    actual=train_actual, predicted=train_predcit\n",
    "                )\n",
    "                valid_performance = self.compute_model_performace(\n",
    "                    actual=valid_actual, predicted=valid_predict\n",
    "                )\n",
    "\n",
    "                for index, performace in enumerate(\n",
    "                    [train_performance, valid_performance]\n",
    "                ):\n",
    "                    for metric, value in performace.items():\n",
    "                        mlflow.log_metric(\n",
    "                            key=\"train_\" + metric if index == 0 else \"valid_\" + metric,\n",
    "                            value=value,\n",
    "                            step=epoch + 1,\n",
    "                        )\n",
    "\n",
    "                for type, loss in [\n",
    "                    (\"train_loss\", np.mean(train_loss)),\n",
    "                    (\"test_loss\", np.mean(test_loss)),\n",
    "                ]:\n",
    "                    mlflow.log_metric(key=type, value=loss, step=epoch + 1)\n",
    "\n",
    "            print(\"Training is completed\".title())\n",
    "\n",
    "            dump(\n",
    "                value=self.history,\n",
    "                filename=os.path.join(config()[\"path\"][\"FILES_PATH\"], \"history.pkl\"),\n",
    "            )\n",
    "\n",
    "            mlflow.log_params(\n",
    "                {\n",
    "                    \"epochs\": self.epochs,\n",
    "                    \"lr\": self.lr,\n",
    "                    \"beta1\": self.beta1,\n",
    "                    \"beta2\": self.beta2,\n",
    "                    \"adam\": self.adam,\n",
    "                    \"SGD\": self.SGD,\n",
    "                    \"momentun\": self.momentum,\n",
    "                    \"device\": self.device,\n",
    "                    \"display\": self.is_display,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            mlflow.pytorch.log_model(self.model, \"Breast_Cancer_Model\")\n",
    "\n",
    "            mlflow.log_artifact(\n",
    "                os.path.join(self.files_path, \"Model.jpeg\"),\n",
    "            )\n",
    "\n",
    "            mlflow.log_artifacts(\n",
    "                os.path.join(\n",
    "                    self.raw_data_path,\n",
    "                ),\n",
    "                artifact_path=\"dataset\",\n",
    "            )\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_history():\n",
    "        plt.figure(figsize=(10, 5))\n",
    "\n",
    "        history = load(\n",
    "            filename=os.path.join(config()[\"path\"][\"FILES_PATH\"], \"history.pkl\")\n",
    "        )\n",
    "\n",
    "        for filename, loss in history.items():\n",
    "            plt.plot(loss, label=filename)\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.legend()\n",
    "\n",
    "        plt.tight_layout\n",
    "        plt.savefig(os.path.join(config()[\"path\"][\"FILES_PATH\"], \"loss.png\"))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Trainer code for Breast Cancer\".title()\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--epochs\",\n",
    "        type=int,\n",
    "        default=config()[\"trainer\"][\"epochs\"],\n",
    "        help=\"Number of epochs\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lr\",\n",
    "        type=float,\n",
    "        default=config()[\"trainer\"][\"lr\"],\n",
    "        help=\"Learning rate\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--beta1\",\n",
    "        type=float,\n",
    "        default=config()[\"trainer\"][\"beta1\"],\n",
    "        help=\"Beta1\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--beta2\",\n",
    "        type=float,\n",
    "        default=config()[\"trainer\"][\"beta2\"],\n",
    "        help=\"Beta2\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--adam\",\n",
    "        type=bool,\n",
    "        default=config()[\"trainer\"][\"adam\"],\n",
    "        help=\"Adam\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--SGD\",\n",
    "        type=bool,\n",
    "        default=config()[\"trainer\"][\"SGD\"],\n",
    "        help=\"SGD\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--display\",\n",
    "        type=bool,\n",
    "        default=config()[\"trainer\"][\"display\"],\n",
    "        help=\"Display\".capitalize(),\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    trainer = Trainer(\n",
    "        epochs=args.epochs,\n",
    "        lr=args.lr,\n",
    "        beta1=args.beta1,\n",
    "        beta2=args.beta2,\n",
    "        adam=args.adam,\n",
    "        SGD=args.SGD,\n",
    "        is_display=args.display,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    trainer.plot_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "from utils import load, config\n",
    "from model import Model\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "\n",
    "class TestModel:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.model = Model()\n",
    "\n",
    "    def load_dataloader(self):\n",
    "        return load(\n",
    "            filename=os.path.join(\n",
    "                config()[\"path\"][\"PROCESSED_PATH\"], \"test_dataloader.pkl\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def select_best_model(self):\n",
    "        if os.path.exists(config()[\"path\"][\"BEST_MODEL_PATH\"]):\n",
    "            best_model_path = config()[\"path\"][\"BEST_MODEL_PATH\"]\n",
    "\n",
    "            best_model = torch.load(os.path.join(best_model_path, \"best_model.pth\"))\n",
    "\n",
    "            self.model.load_state_dict(best_model[\"model\"])\n",
    "\n",
    "    def saved_performace(self, **kwargs):\n",
    "        with open(\n",
    "            os.path.join(config()[\"path\"][\"OUTPUTS_PATH\"], \"valid_performace.txt\"), \"w\"\n",
    "        ) as file:\n",
    "            file.write(\n",
    "                \"Accuracy: {}\\nPrecision:{}\\nRecall:{}\\nF1_Score:{}\\n{}\".format(\n",
    "                    str(kwargs[\"accuracy\"]),\n",
    "                    str(kwargs[\"precision\"]),\n",
    "                    str(kwargs[\"recall\"]),\n",
    "                    str(kwargs[\"f1_score\"]),\n",
    "                    \"*\" * 100,\n",
    "                )\n",
    "            )\n",
    "            file.write(\n",
    "                \"\\nConfusion Metrics\\n{}\\n{}\".format(\n",
    "                    str(confusion_matrix(kwargs[\"y_true\"], kwargs[\"y_pred\"])), \"*\" * 100\n",
    "                )\n",
    "            )\n",
    "            file.write(\n",
    "                \"\\nClassification report\\n\\n{}:\\n\".format(\n",
    "                    str(classification_report(kwargs[\"y_true\"], kwargs[\"y_pred\"]))\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def test(self):\n",
    "        dataloader = self.load_dataloader()\n",
    "\n",
    "        print(dataloader)\n",
    "\n",
    "        self.select_best_model()\n",
    "\n",
    "        self.predicted = []\n",
    "        self.actual = []\n",
    "\n",
    "        for X, y in dataloader:\n",
    "            X = X.float()\n",
    "            y = y.float()\n",
    "\n",
    "            predicted = self.model(X)\n",
    "            predicted = predicted.view(-1)\n",
    "            predicted = torch.where(predicted > 0.5, 1, 0)\n",
    "            predicted = predicted.detach().flatten()\n",
    "\n",
    "            self.actual.extend(y.detach().flatten())\n",
    "            self.predicted.extend(predicted)\n",
    "\n",
    "        accuracy = accuracy_score(self.predicted, self.actual)\n",
    "        precision = precision_score(self.predicted, self.actual)\n",
    "        recall = recall_score(self.predicted, self.actual)\n",
    "        f1 = f1_score(self.predicted, self.actual)\n",
    "\n",
    "        confusion = confusion_matrix(self.predicted, self.actual)\n",
    "        classification = classification_report(self.predicted, self.actual)\n",
    "\n",
    "        self.saved_performace(\n",
    "            accuracy=accuracy,\n",
    "            precision=precision,\n",
    "            recall=recall,\n",
    "            f1_score=f1,\n",
    "            y_true=self.actual,\n",
    "            y_pred=self.predicted,\n",
    "        )\n",
    "\n",
    "        print(f\"Test Accuracy: {accuracy}\")\n",
    "        print(f\"Test Precision: {precision}\")\n",
    "        print(f\"Test Recall: {recall}\")\n",
    "        print(f\"Test F1 Score: {f1}\")\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "        print(f\"Confusion Matrix: \\n {confusion}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "        print(f\"Classification Report: \\n {classification}\")\n",
    "\n",
    "        print(\n",
    "            \"Model performace saved in the folder {}\".format(\n",
    "                config()[\"path\"][\"OUTPUTS_PATH\"]\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Test Model for Breast Cancer\".title())\n",
    "    parser.add_argument(\"--test\", action=\"store_true\", help=\"Test Model\".capitalize())\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.test:\n",
    "        test = TestModel()\n",
    "\n",
    "        test.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from tester import TestModel\n",
    "from trainer import Trainer\n",
    "from dataloader import Loader\n",
    "from utils import config\n",
    "\n",
    "\n",
    "def train_test_model(**kwargs):\n",
    "    if kwargs[\"train\"]:\n",
    "        loader = Loader(\n",
    "            dataset=kwargs[\"dataset\"],\n",
    "            batch_size=kwargs[\"batch_size\"],\n",
    "            split_size=kwargs[\"split_size\"],\n",
    "        )\n",
    "        loader.create_dataloader()\n",
    "\n",
    "        trainer = Trainer(\n",
    "            epochs=kwargs[\"epochs\"],\n",
    "            lr=kwargs[\"lr\"],\n",
    "            beta1=kwargs[\"beta1\"],\n",
    "            beta2=kwargs[\"beta2\"],\n",
    "            adam=kwargs[\"adam\"],\n",
    "            SGD=kwargs[\"SGD\"],\n",
    "            is_display=kwargs[\"display\"],\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "\n",
    "        trainer.plot_history()\n",
    "\n",
    "    elif kwargs[\"test\"]:\n",
    "        test = TestModel()\n",
    "        test.test()\n",
    "\n",
    "\n",
    "def cli():\n",
    "    parser = argparse.ArgumentParser(description=\"CLI for the project\".capitalize())\n",
    "\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Data Loader for the Cancer\".capitalize()\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dataset\",\n",
    "        default=os.path.join(config()[\"path\"][\"RAW_PATH\"], \"breast-cancer.csv\"),\n",
    "        help=\"Defin the dataset\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--split_size\",\n",
    "        default=config()[\"data\"][\"split_size\"],\n",
    "        type=float,\n",
    "        help=\"Defin the split size\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        default=config()[\"data\"][\"batch_size\"],\n",
    "        type=int,\n",
    "        help=\"Defin the batch size\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--epochs\",\n",
    "        type=int,\n",
    "        default=config()[\"trainer\"][\"epochs\"],\n",
    "        help=\"Number of epochs\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lr\",\n",
    "        type=float,\n",
    "        default=config()[\"trainer\"][\"lr\"],\n",
    "        help=\"Learning rate\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--beta1\",\n",
    "        type=float,\n",
    "        default=config()[\"trainer\"][\"beta1\"],\n",
    "        help=\"Beta1\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--beta2\",\n",
    "        type=float,\n",
    "        default=config()[\"trainer\"][\"beta2\"],\n",
    "        help=\"Beta2\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--adam\",\n",
    "        type=bool,\n",
    "        default=config()[\"trainer\"][\"adam\"],\n",
    "        help=\"Adam\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--SGD\",\n",
    "        type=bool,\n",
    "        default=config()[\"trainer\"][\"SGD\"],\n",
    "        help=\"SGD\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--display\",\n",
    "        type=bool,\n",
    "        default=config()[\"trainer\"][\"display\"],\n",
    "        help=\"Display\".capitalize(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--config\",\n",
    "        default=None,\n",
    "        help=\"Config file to train and test the model\".capitalize(),\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\"--train\", action=\"store_true\", help=\"Train Model\".capitalize())\n",
    "    parser.add_argument(\"--test\", action=\"store_true\", help=\"Test Model\".capitalize())\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.config is not None:\n",
    "        train_test_model(\n",
    "            train=args.train,\n",
    "            test=args.test,\n",
    "            dataset=os.path.join(config()[\"path\"][\"RAW_PATH\"], \"breast-cancer.csv\"),\n",
    "            batch_size=config()[\"data\"][\"batch_size\"],\n",
    "            split_size=config()[\"data\"][\"split_size\"],\n",
    "            epochs=config()[\"trainer\"][\"epochs\"],\n",
    "            lr=config()[\"trainer\"][\"lr\"],\n",
    "            beta1=config()[\"trainer\"][\"beta1\"],\n",
    "            beta2=config()[\"trainer\"][\"beta2\"],\n",
    "            adam=config()[\"trainer\"][\"adam\"],\n",
    "            SGD=config()[\"trainer\"][\"SGD\"],\n",
    "            display=config()[\"trainer\"][\"display\"],\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        train_test_model(\n",
    "            train=args.train,\n",
    "            test=args.test,\n",
    "            dataset=args.dataset,\n",
    "            batch_size=args.batch_size,\n",
    "            split_size=args.split_size,\n",
    "            epochs=args.epochs,\n",
    "            lr=args.lr,\n",
    "            beta1=args.beta1,\n",
    "            beta2=args.beta2,\n",
    "            adam=args.adam,\n",
    "            SGD=args.SGD,\n",
    "            display=args.display,\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cli()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPSG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
